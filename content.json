{"meta":{"title":"黄骞的博客","subtitle":"被代码耽误的厨师","description":null,"author":"黄骞","url":"http://huangqian.site"},"pages":[],"posts":[{"title":"控制哪些主机是Coordinators和Executors","slug":"controlling-which-hosts-are-coordinators-and-executors","date":"2018-01-15T09:08:43.000Z","updated":"2018-01-16T07:01:45.000Z","comments":true,"path":"2018/01/15/controlling-which-hosts-are-coordinators-and-executors/","link":"","permalink":"http://huangqian.site/2018/01/15/controlling-which-hosts-are-coordinators-and-executors/","excerpt":"","text":"默认情况下，运行impalad后台驻留程序的群集中的每个主机都可以充当Impala查询的协调者，执行查询执行计划的片段或两者。在大规模查询的高度并发工作负载（尤其是大型集群）期间，双重角色可能导致可伸缩性问题： 主机担任协调器所需的额外工作可能会干扰其在查询的早期阶段执行其他工作的能力。例如，在包含大量查询片段的查询期间，协调器可能会遇到显着的网络和CPU开销。每个协调器缓存所有表分区和数据文件的元数据，这些数据文件可能很大，并与处理由查询执行器执行的连接，聚合和其他操作所需的内存竞争。 大量主机充当协调器可能会导致不必要的网络开销甚至超时错误，因为每个主机都与状态存储后台进程通信以进行元数据更新。 当有大量负载较重的主机充当协调者时，由准入控制功能施加的“软限制”更可能被超过。 如果出现这种可伸缩性瓶颈，则可以明确指定某些主机充当查询协调器，而不是查询片段的执行器。这些主机不参与扫描等I/O密集型操作，以及聚合等CPU密集型操作。 然后，您指定其他主机充当执行器，但不是协调器。这些主机不会与statestored的守护进程通信或处理来自查询的最终结果集。您无法通过客户端（如impala-shell或商业智能工具）连接到这些主机。 此功能在CDH 5.12 / Impala 2.9及更高版本中可用。 要使用此功能，请在每个主机上为impalad后台驻留程序指定以下启动标志之一： is_executor = falseforeachhost，它不作为查询协调者。此设置通常适用于相对较少数量的主机，因为最常见的拓扑结构是几乎所有DataNode都在为查询执行工作。 is_coordinator = false。对于不充当Impala查询协调者的每个主机，这些东道主完全是执行者。具有此设置的主机数量通常随着集群变大并处理更多的表分区，数据文件和并发查询而增加。随着查询协调的开销增加，将这些工作集中在专用主机上变得更加重要。 默认情况下，这两个设置都为每个impalad实例启用，允许所有这些主机同时担任执行者和协调者。 例如，在100个节点的集群上，可以为10个主机指定is_executor = false，将这些主机专用为查询协调器。然后为其余的90个主机指定is_coordinator = false。所有显式或负载均衡的连接都必须作为协调者的10个主机。这些主机执行网络通信以保持元数据最新并将查询结果传送给适当的客户端。其余的90个主机执行构成每个查询的大部分工作的密集I/O，CPU和内存操作。如果特定主机上出现瓶颈或其他性能问题，则可以更轻松地缩小原因，因为每个主机都专门用于整个Impala工作负载中的特定操作。","categories":[{"name":"Impala","slug":"Impala","permalink":"http://huangqian.site/categories/Impala/"}],"tags":[{"name":"impala","slug":"impala","permalink":"http://huangqian.site/tags/impala/"},{"name":"warehouse","slug":"warehouse","permalink":"http://huangqian.site/tags/warehouse/"}]},{"title":"新目标起航","slug":"start-blog","date":"2018-01-15T04:02:52.000Z","updated":"2018-01-16T07:01:53.000Z","comments":true,"path":"2018/01/15/start-blog/","link":"","permalink":"http://huangqian.site/2018/01/15/start-blog/","excerpt":"","text":"开始的缘由 新年伊始，突然有了写东西的想法。2017年，有很多东西需要总结，有些记录在自己的git的note里面，有一些在公司的专栏博客里面，还有一些在“等有空的时候”流失了。很可惜，这些是自己的成长的记录。于是乎，决定自己构建博客，把日常工作、学习的知识，做一些总结和记录。日后也可看看自己的记录，犯过的错，督促自己学习进步！ 方向2017年，我阅读了storm和kafka的源码，弄清楚了很多东西，对于我的架构设计和性能优化帮助很大，可惜的是这些笔记和自己的思考没有记录下来。2018年的几个方向： Kudu： 新的大数据存储平台，在事件分析平台和数据仓库中大规模使用。其主键和事物能够提供一定幂等性，搭配impala提供不错的查询性能，写入方案先写入内存，定期刷盘，这可以提高写入性能，也能解决hive作为数据接入层大量的小文件问题。 impala：SQL引擎中计算性能不错，目前最适合即时响应的方案。同时支持hive、kudu，作为数据仓库非常不错的方案。 druid： 能做解决多维度roll-up数据的存储，并且能够有良好的响应速度。适合多维的统计结果存储和非事件原子粒度的分析平台存储方案。 spark： 数据挖掘目前应用最广的平台 flink： 发展趋势不错的计算平台，未来可能会替代spark在实时和离线的方向 beam： 统一编程模型框架 hadoop hdfs： 深层次的原理探索，源码分析 yarn：深层次的原理探索，源码分析，构建应用 lisp clojure scheme 目标在今年，尽量保持一周\b1-3篇的节奏。","categories":[{"name":"生活","slug":"life","permalink":"http://huangqian.site/categories/life/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://huangqian.site/tags/随笔/"}]}]}